{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z5D Resonance Scoring Hypothesis Validation\n",
    "\n",
    "**Issue #16**: Validate Z5D resonance scoring hypothesis using N₁₂₇ ground truth\n",
    "\n",
    "This notebook analyzes whether the Z5D geometric scoring algorithm effectively guides factorization searches by concentrating candidate factors near the true divisors better than random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Add parent directory for imports\n",
    "sys.path.insert(0, str(Path('.').parent.resolve()))\n",
    "\n",
    "# Style settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ground Truth Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth from Issue #16\n",
    "N_127 = 137524771864208156028430259349934309717\n",
    "SQRT_N = 11727095627827384440\n",
    "P_TRUE = 10508623501177419659\n",
    "Q_TRUE = 13086849276577416863\n",
    "\n",
    "# Search window (±13%)\n",
    "SEARCH_RADIUS = (SQRT_N * 13) // 100\n",
    "SEARCH_MIN = SQRT_N - SEARCH_RADIUS\n",
    "SEARCH_MAX = SQRT_N + SEARCH_RADIUS\n",
    "SEARCH_WIDTH = SEARCH_MAX - SEARCH_MIN\n",
    "\n",
    "# Relative positions of factors within search window\n",
    "P_RELATIVE = (P_TRUE - SEARCH_MIN) / SEARCH_WIDTH\n",
    "Q_RELATIVE = (Q_TRUE - SEARCH_MIN) / SEARCH_WIDTH\n",
    "\n",
    "print(\"Ground Truth:\")\n",
    "print(f\"  N₁₂₇ = {N_127}\")\n",
    "print(f\"  √N   = {SQRT_N}\")\n",
    "print(f\"  p    = {P_TRUE} (offset: {(P_TRUE - SQRT_N) / SQRT_N * 100:.2f}%)\")\n",
    "print(f\"  q    = {Q_TRUE} (offset: {(Q_TRUE - SQRT_N) / SQRT_N * 100:.2f}%)\")\n",
    "print(f\"\\nSearch Window:\")\n",
    "print(f\"  [{SEARCH_MIN}, {SEARCH_MAX}]\")\n",
    "print(f\"  Width: {SEARCH_WIDTH}\")\n",
    "print(f\"\\nFactor Positions (normalized 0-1):\")\n",
    "print(f\"  p: {P_RELATIVE:.4f}\")\n",
    "print(f\"  q: {Q_RELATIVE:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from the validation run\n",
    "results_path = Path('../artifacts/validation/z5d_validation_results.json')\n",
    "top_candidates_path = Path('../artifacts/validation/top_candidates.jsonl')\n",
    "\n",
    "# Check if files exist, otherwise use test results\n",
    "if not results_path.exists():\n",
    "    results_path = Path('../artifacts/validation_test/z5d_validation_results.json')\n",
    "    top_candidates_path = Path('../artifacts/validation_test/top_candidates.jsonl')\n",
    "\n",
    "with open(results_path) as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Load top candidates\n",
    "top_candidates = []\n",
    "with open(top_candidates_path) as f:\n",
    "    for line in f:\n",
    "        top_candidates.append(json.loads(line))\n",
    "\n",
    "df_top = pd.DataFrame(top_candidates)\n",
    "\n",
    "print(f\"Loaded results from: {results_path}\")\n",
    "print(f\"\\nExperiment Parameters:\")\n",
    "print(f\"  Samples: {results['metadata']['samples']:,}\")\n",
    "print(f\"  Top fraction: {results['metadata']['top_fraction']:.2%}\")\n",
    "print(f\"  Scoring time: {results['metadata']['scoring_time_s']:.1f}s\")\n",
    "print(f\"\\nTop candidates loaded: {len(df_top)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Z5D Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of Z5D scores\n",
    "ax1 = axes[0]\n",
    "ax1.hist(df_top['z5d_score'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax1.axvline(df_top['z5d_score'].median(), color='red', linestyle='--', \n",
    "            label=f'Median: {df_top[\"z5d_score\"].median():.2f}')\n",
    "ax1.set_xlabel('Z5D Score (lower = better PNT alignment)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Z5D Scores (Top Candidates)')\n",
    "ax1.legend()\n",
    "\n",
    "# Score vs Position scatter\n",
    "ax2 = axes[1]\n",
    "scatter = ax2.scatter(df_top['relative_position'], df_top['z5d_score'], \n",
    "                       c=df_top['z5d_score'], cmap='RdYlGn_r', alpha=0.6, s=20)\n",
    "ax2.axvline(P_RELATIVE, color='green', linestyle='-', linewidth=2, label=f'True p ({P_RELATIVE:.3f})')\n",
    "ax2.axvline(Q_RELATIVE, color='blue', linestyle='-', linewidth=2, label=f'True q ({Q_RELATIVE:.3f})')\n",
    "ax2.set_xlabel('Relative Position in Search Window')\n",
    "ax2.set_ylabel('Z5D Score')\n",
    "ax2.set_title('Z5D Score vs Position (with True Factor Locations)')\n",
    "ax2.legend()\n",
    "plt.colorbar(scatter, ax=ax2, label='Z5D Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../artifacts/validation/z5d_score_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Calculate distances\n",
    "df_top['dist_to_p_norm'] = df_top['dist_to_p'] / SEARCH_WIDTH\n",
    "df_top['dist_to_q_norm'] = df_top['dist_to_q'] / SEARCH_WIDTH\n",
    "df_top['min_dist'] = df_top[['dist_to_p_norm', 'dist_to_q_norm']].min(axis=1)\n",
    "\n",
    "# 1. Position histogram\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(df_top['relative_position'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax1.axvline(P_RELATIVE, color='green', linestyle='-', linewidth=2, label=f'True p')\n",
    "ax1.axvline(Q_RELATIVE, color='blue', linestyle='-', linewidth=2, label=f'True q')\n",
    "ax1.set_xlabel('Relative Position in Search Window')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Spatial Distribution of Top Z5D Candidates')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Distance to factors histogram\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(df_top['min_dist'], bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "ax2.axvline(df_top['min_dist'].mean(), color='red', linestyle='--', \n",
    "            label=f'Mean: {df_top[\"min_dist\"].mean():.4f}')\n",
    "ax2.axvline(df_top['min_dist'].median(), color='darkred', linestyle=':', \n",
    "            label=f'Median: {df_top[\"min_dist\"].median():.4f}')\n",
    "ax2.set_xlabel('Min Distance to True Factor (normalized)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distance Distribution: Top Candidates to Nearest Factor')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. 2D density: position vs score\n",
    "ax3 = axes[1, 0]\n",
    "hist2d = ax3.hist2d(df_top['relative_position'], df_top['z5d_score'], \n",
    "                     bins=30, cmap='Blues')\n",
    "ax3.axvline(P_RELATIVE, color='green', linestyle='-', linewidth=2)\n",
    "ax3.axvline(Q_RELATIVE, color='blue', linestyle='-', linewidth=2)\n",
    "ax3.set_xlabel('Relative Position')\n",
    "ax3.set_ylabel('Z5D Score')\n",
    "ax3.set_title('2D Density: Position vs Z5D Score')\n",
    "plt.colorbar(hist2d[3], ax=ax3, label='Count')\n",
    "\n",
    "# 4. Cumulative distribution comparison\n",
    "ax4 = axes[1, 1]\n",
    "sorted_distances = np.sort(df_top['min_dist'])\n",
    "uniform_distances = np.linspace(0, 0.5, len(sorted_distances))  # Expected uniform\n",
    "\n",
    "ax4.plot(sorted_distances, np.arange(1, len(sorted_distances)+1)/len(sorted_distances), \n",
    "         'b-', linewidth=2, label='Top Z5D Candidates')\n",
    "ax4.plot(uniform_distances, np.arange(1, len(uniform_distances)+1)/len(uniform_distances), \n",
    "         'r--', linewidth=2, label='Expected Uniform')\n",
    "ax4.set_xlabel('Distance to Nearest Factor (normalized)')\n",
    "ax4.set_ylabel('Cumulative Probability')\n",
    "ax4.set_title('CDF: Top Candidates vs Expected Uniform Distribution')\n",
    "ax4.legend()\n",
    "ax4.set_xlim(0, 0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../artifacts/validation/spatial_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STATISTICAL TEST RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Enrichment Analysis\n",
    "enrichment = results['enrichment']\n",
    "print(f\"\\nENRICHMENT ANALYSIS:\")\n",
    "print(f\"  Candidates near p: {enrichment['near_p']}\")\n",
    "print(f\"  Candidates near q: {enrichment['near_q']}\")\n",
    "print(f\"  Candidates near either: {enrichment['near_either']}\")\n",
    "print(f\"  Expected by chance: {enrichment['expected_count']:.1f}\")\n",
    "print(f\"  Enrichment Factor: {enrichment['enrichment_factor']:.2f}x\")\n",
    "\n",
    "# K-S Test\n",
    "ks = results['statistical_tests']['ks_test']\n",
    "print(f\"\\nKOLMOGOROV-SMIRNOV TEST:\")\n",
    "print(f\"  Statistic: {ks['statistic']:.4f}\")\n",
    "print(f\"  P-value: {ks['p_value']:.2e}\")\n",
    "print(f\"  Significant (p<0.001): {ks['significant_001']}\")\n",
    "\n",
    "# Mann-Whitney U Test  \n",
    "mw = results['statistical_tests']['mann_whitney']\n",
    "print(f\"\\nMANN-WHITNEY U TEST:\")\n",
    "print(f\"  Statistic: {mw['statistic']:.2e}\")\n",
    "print(f\"  P-value: {mw['p_value']:.2e}\")\n",
    "print(f\"  Significant (p<0.001): {mw['significant_001']}\")\n",
    "\n",
    "# Distance Summary\n",
    "summary = results['statistical_tests']['summary']\n",
    "print(f\"\\nDISTANCE SUMMARY:\")\n",
    "print(f\"  Top candidates mean distance: {summary['top_mean_distance']:.4f}\")\n",
    "print(f\"  Baseline mean distance: {summary['baseline_mean_distance']:.4f}\")\n",
    "print(f\"  Distance ratio (top/baseline): {summary['distance_ratio']:.4f}\")\n",
    "\n",
    "# Signal Classification\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"SIGNAL CLASSIFICATION: {results['signal_classification']}\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization: Top vs Random Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "summary = results['statistical_tests']['summary']\n",
    "\n",
    "# Bar chart comparison\n",
    "ax1 = axes[0]\n",
    "categories = ['Mean Distance\\nto Factor', 'Median Distance\\nto Factor']\n",
    "top_values = [summary['top_mean_distance'], summary['top_median_distance']]\n",
    "baseline_values = [summary['baseline_mean_distance'], summary['baseline_median_distance']]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, top_values, width, label='Top Z5D Candidates', color='steelblue')\n",
    "bars2 = ax1.bar(x + width/2, baseline_values, width, label='Random Baseline', color='coral')\n",
    "\n",
    "ax1.set_ylabel('Distance (normalized)')\n",
    "ax1.set_title('Top Z5D Candidates vs Random Baseline')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(categories)\n",
    "ax1.legend()\n",
    "ax1.bar_label(bars1, fmt='%.4f', padding=3)\n",
    "ax1.bar_label(bars2, fmt='%.4f', padding=3)\n",
    "\n",
    "# Effect size visualization\n",
    "ax2 = axes[1]\n",
    "metrics = ['Distance\\nRatio', 'Enrichment\\nFactor', 'K-S\\nStatistic']\n",
    "values = [summary['distance_ratio'], \n",
    "          min(enrichment['enrichment_factor'], 10),  # Cap for visualization\n",
    "          ks['statistic']]\n",
    "colors = ['green' if v < 1 or v > 0.5 else 'red' for v in values]\n",
    "colors = ['green', 'steelblue', 'coral']  # Override with meaningful colors\n",
    "\n",
    "bars = ax2.bar(metrics, values, color=colors, edgecolor='black')\n",
    "ax2.axhline(1.0, color='red', linestyle='--', label='Null hypothesis (no effect)')\n",
    "ax2.set_ylabel('Value')\n",
    "ax2.set_title('Effect Size Metrics')\n",
    "ax2.legend()\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "             f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../artifacts/validation/comparison_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Z5D HYPOTHESIS VALIDATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"HYPOTHESIS: Z5D resonance scoring concentrates candidate factors\")\n",
    "print(\"            near true divisors better than random sampling.\")\n",
    "print()\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(f\"  1. Distance ratio: {summary['distance_ratio']:.4f}\")\n",
    "print(f\"     → Top candidates are {1/summary['distance_ratio']:.1f}x closer to factors than random\")\n",
    "print()\n",
    "print(f\"  2. Mann-Whitney U p-value: {mw['p_value']:.2e}\")\n",
    "print(f\"     → Highly statistically significant (p < 0.001)\")\n",
    "print()\n",
    "print(f\"  3. K-S test statistic: {ks['statistic']:.4f}\")\n",
    "print(f\"     → Distribution differs significantly from random baseline\")\n",
    "print()\n",
    "\n",
    "signal = results['signal_classification']\n",
    "print(\"=\" * 70)\n",
    "if signal == \"STRONG\":\n",
    "    print(\"CONCLUSION: STRONG SIGNAL - HYPOTHESIS SUPPORTED\")\n",
    "    print()\n",
    "    print(\"The Z5D scoring algorithm demonstrates a statistically significant\")\n",
    "    print(\"ability to concentrate candidate factors near the true divisors of N₁₂₇.\")\n",
    "    print(\"Top-ranked candidates are substantially closer to the factors than\")\n",
    "    print(\"would be expected by random chance.\")\n",
    "elif signal == \"WEAK\":\n",
    "    print(\"CONCLUSION: WEAK SIGNAL - HYPOTHESIS PARTIALLY SUPPORTED\")\n",
    "    print()\n",
    "    print(\"The Z5D scoring algorithm shows some preference for factor regions,\")\n",
    "    print(\"but the effect size is moderate. Further investigation with larger\")\n",
    "    print(\"sample sizes may strengthen or weaken these findings.\")\n",
    "else:\n",
    "    print(\"CONCLUSION: NO SIGNAL - HYPOTHESIS NOT SUPPORTED\")\n",
    "    print()\n",
    "    print(\"The Z5D scoring algorithm does not appear to concentrate candidates\")\n",
    "    print(\"near the true factors any better than random sampling.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Appendix: Top 20 Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 20 candidates with their properties\n",
    "display_cols = ['candidate', 'z5d_score', 'dist_to_p', 'dist_to_q', 'relative_position']\n",
    "df_display = df_top[display_cols].head(20).copy()\n",
    "df_display['candidate'] = df_display['candidate'].apply(lambda x: f\"{int(x):,}\")\n",
    "df_display['dist_to_p'] = df_display['dist_to_p'].apply(lambda x: f\"{x:,.0f}\")\n",
    "df_display['dist_to_q'] = df_display['dist_to_q'].apply(lambda x: f\"{x:,.0f}\")\n",
    "df_display.columns = ['Candidate', 'Z5D Score', 'Dist to p', 'Dist to q', 'Rel Position']\n",
    "\n",
    "print(\"TOP 20 Z5D-RANKED CANDIDATES\")\n",
    "print(\"=\" * 100)\n",
    "print(df_display.to_string(index=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
